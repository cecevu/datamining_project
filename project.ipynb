{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a0115f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e87a67",
   "metadata": {},
   "source": [
    "## Group Members ##\n",
    "Cecilia Vu,\n",
    "Julianne Vu,\n",
    "An Vi Nguyen,\n",
    "Emaan Haseem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fcb535",
   "metadata": {},
   "source": [
    "## Introduction ##\n",
    "For our project, we are trying to predict whether or not an animal will be adopted based their characteristics. This problem is important as there are thousands of animals placed in shelters each year and our model could help these animals get adopted and avoid euthanasia. The dataset that we are using from for model is from the Austin Animal Center. This dataset provides the characteristics of the animals when they arrived at the center as well as their characteristics when they leave the center. These features includes their condition, breed, age, etc. We will use this dataset to build a model to predict whether or not an animal will be adopted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0632f0",
   "metadata": {},
   "source": [
    "## Data Collection ##\n",
    "We are merging the data based on their Animal ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4131163",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Austin_Animal_Center_Intakes.csv')\n",
    "data2 = pd.read_csv('Austin_Animal_Center_Outcomes.csv')\n",
    "\n",
    "data = pd.merge(data1, data2, on='Animal ID', how='inner')\n",
    "data_copy = data.copy()\n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b17bc",
   "metadata": {},
   "source": [
    "## Feature Selection ##\n",
    "For feature selection, we dropped the following labels/columns from our merged dataset:\n",
    "* **Name_x, Name_y**\n",
    "    * We used the row indices to identify the animals instead of the names, this way it would be numeric and unique.\n",
    "* **MonthYear_x, MonthYear_y**\n",
    "    * We already have DateTime_x and DateTime_y, so having MonthYear was not necessary. \n",
    "* **Found Location**\n",
    "    * Majority of the found location was in Austin, TX and we didn't think Found Location was relevant enough to affect our predictions.\n",
    "* **Animal Type_y, Color_y, Breed_y**\n",
    "    * Since we already got Animal Type_x, Color_x, and Breed_x, these three y columns were duplicates, so we didn't need them.\n",
    "* **Outcome Subtype**\n",
    "    * We already have Outcome Type, and we only cared whether an animal was adopted or not. Dropping the subtype would simplify our prediction.\n",
    "* **Date of Birth, Age upon Outcome**\n",
    "    * We already have Age upon Intake and how long they had been at the center, so date of birth and age upon outcome was not necessary. \n",
    "* **Sex upon Intake**\n",
    "    * They could've been neutered or spayed during their time at the shelter, so their sex upon outcome was more relevant for our dataset and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b87f22f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178310, 11)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['Name_x','MonthYear_x','MonthYear_y','Found Location','Name_y','Animal Type_y','Color_y','Breed_y','Outcome Subtype','Date of Birth', 'Age upon Outcome', 'Sex upon Intake'])\n",
    "#print(data.head())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4679dd3",
   "metadata": {},
   "source": [
    "## Data Cleaning/Prep ##\n",
    "\n",
    "For data cleaning, we dropped all rows that contained N/A, NaN or Unknown. We also decided to drop all rows with duplicate animal IDs because they could have been adopted out and returned back to the center multiple times, and it would be difficult to track how long they were actually at the center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dd94aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100607, 11)\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data = data.loc[data['Sex upon Outcome'] != 'Unknown']\n",
    "data.drop_duplicates(subset='Animal ID', keep = False, inplace = True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a5a3d",
   "metadata": {},
   "source": [
    "Since the ages were formatted as \"X years\", \"X months\" or \"X weeks,\" we decided to standardized it to weeks so we can better can compare the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd6f0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting age into number of weeks\n",
    "for i in range(len(data)):\n",
    "    age = str(data.iloc[i,5])\n",
    "    age = age.split()\n",
    "    if len(age) < 2:\n",
    "        data.drop(i)\n",
    "        continue\n",
    "    if (age[1] == 'years' or age[1] == 'year'):\n",
    "        data.iloc[i,5] = int(age[0]) * 52\n",
    "    elif (age[1] == 'months' or age[1] == 'month'):\n",
    "        data.iloc[i,5] = int(age[0]) * 4\n",
    "    else:\n",
    "        data.iloc[i,5] = int(age[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466be1e",
   "metadata": {},
   "source": [
    "We split our data into two data sets, features and labels. We used that 'Outcome Type' as the label dataframe. However, there more than 2 categories in the label dataset and we only cared about predicting whether or not the animals were adopted. We decided to change the label set to a binary and set all of the 'Adoption' labels to 1 and the others to 0. We thought that this would help simplify our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dfc9919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature data frame:  (100607, 9)\n",
      "length of label data frame:  100607\n",
      "48288\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "label_df = data['Outcome Type']\n",
    "feature_df = data.drop(columns=['Outcome Type', 'Animal ID'])\n",
    "label_df = label_df.values.ravel()\n",
    "print(\"shape of feature data frame: \", feature_df.shape)\n",
    "print(\"length of label data frame: \" , len(label_df))\n",
    "\n",
    "for i in range(len(label_df)):\n",
    "    if label_df[i] == 'Adoption' or label_df[i] == 1:\n",
    "        label_df[i] = 1\n",
    "    else:\n",
    "        label_df[i] = 0\n",
    "print(sum(label_df))\n",
    "print(label_df)\n",
    "#feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf556b",
   "metadata": {},
   "source": [
    "After that, we decided to factorize all the categorical data into numeric data. We attempted to do one-hot-encoding; however, our dimensionality increase by a lot since there were so many categories for breed and colors which would make it harder to efficiently generalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "559de5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['Animal Type_x'] = pd.factorize(feature_df['Animal Type_x'])[0]\n",
    "feature_df['Intake Type'] = pd.factorize(feature_df['Intake Type'])[0]\n",
    "feature_df['Intake Condition'] = pd.factorize(feature_df['Intake Condition'])[0]\n",
    "feature_df['Breed_x'] = pd.factorize(feature_df['Breed_x'])[0]\n",
    "feature_df['Color_x'] = pd.factorize(feature_df['Color_x'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee8a36",
   "metadata": {},
   "source": [
    "We decided to compare the columns DateTime_x and DateTime_y, so we could calculate how long the animal was at the shelter. We did this by converting the DateTimes from strings to DateTime objects and subtracting DateTime_x from DateTime_y. After we got the duration times for each animal, we removed the DateTime columns and added a Duration column because it was more relevant for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30e35915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "durations = []\n",
    "\n",
    "for i in range(len(feature_df)):\n",
    "    into_shelter = datetime.strptime(feature_df.iloc[i, 0], \"%m/%d/%Y %H:%M:%S %p\")\n",
    "    out_shelter = datetime.strptime(feature_df.iloc[i, 7], \"%m/%d/%Y %H:%M:%S %p\")\n",
    "    duration = out_shelter - into_shelter\n",
    "    duration = duration.days\n",
    "    duration = duration if duration >= 0 else 0\n",
    "    durations.append(duration)\n",
    "    \n",
    "feature_df = feature_df.drop(columns=['DateTime_x', 'DateTime_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8577c3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type_x</th>\n",
       "      <th>Age upon Intake</th>\n",
       "      <th>Breed_x</th>\n",
       "      <th>Color_x</th>\n",
       "      <th>Sex upon Outcome</th>\n",
       "      <th>Duration_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intake Type  Intake Condition  Animal Type_x Age upon Intake  Breed_x  \\\n",
       "0            0                 0              0             104        0   \n",
       "1            0                 0              0             416        1   \n",
       "2            0                 0              0              44        2   \n",
       "3            0                 1              1               4        3   \n",
       "4            0                 0              0             208        4   \n",
       "\n",
       "   Color_x Sex upon Outcome  Duration_days  \n",
       "0        0    Neutered Male              4  \n",
       "1        1    Spayed Female              0  \n",
       "2        2    Neutered Male              6  \n",
       "3        3    Intact Female              0  \n",
       "4        4    Neutered Male              2  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df['Duration_days'] = durations\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16b7f0",
   "metadata": {},
   "source": [
    "Sex upon Outcome gave us the neuter/spay status of the animal as well as the sex, but we thought it would more useful to split up this column into two separate columns to analyze trends better. There could be trends from solely the sex of the animal or from solely the neuter/spay status of the animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "644e6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting \"Sex Upon Outcome\" into 2 columns\n",
    "fertility = []\n",
    "gender = []\n",
    "\n",
    "feature_df = feature_df.loc[feature_df['Sex upon Outcome'] != 'Unknown']\n",
    "for i in range(len(feature_df)):\n",
    "    sex = feature_df.iloc[i, 6].split()\n",
    "    sex[0] = 0 if sex[0] == 'Intact' else 1\n",
    "    sex[1] = 0 if sex[1] == 'Male' else 1\n",
    "    fertility.append(sex[0])\n",
    "    gender.append(sex[1])\n",
    "        \n",
    "feature_df = feature_df.drop(columns=['Sex upon Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c418b6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100607, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type_x</th>\n",
       "      <th>Age upon Intake</th>\n",
       "      <th>Breed_x</th>\n",
       "      <th>Color_x</th>\n",
       "      <th>Duration_days</th>\n",
       "      <th>Spayed/Neutered</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intake Type  Intake Condition  Animal Type_x Age upon Intake  Breed_x  \\\n",
       "0            0                 0              0             104        0   \n",
       "1            0                 0              0             416        1   \n",
       "2            0                 0              0              44        2   \n",
       "3            0                 1              1               4        3   \n",
       "4            0                 0              0             208        4   \n",
       "\n",
       "   Color_x  Duration_days  Spayed/Neutered  Gender  \n",
       "0        0              4                1       0  \n",
       "1        1              0                1       1  \n",
       "2        2              6                1       0  \n",
       "3        3              0                0       1  \n",
       "4        4              2                1       0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df['Spayed/Neutered'] = fertility\n",
    "feature_df['Gender'] = gender\n",
    "print(feature_df.shape)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de938952",
   "metadata": {},
   "source": [
    "## Data Analysis ##\n",
    "We needed to split our data into two sets, the training set and the testing set, to build our models. We decided to build our first model using decision trees and we received an accuracy of 81%. However, we realized that we used factorization and instead of one-hot-encoding for our categorical variables, therefore, decision trees would not really work for our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "928fdcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80485\n",
      "20122\n",
      "Accuracy =  0.8051883510585429\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_feat, test_feat, train_label, test_label = train_test_split(feature_df, label_df, train_size = .8, test_size=.2)\n",
    "print(len(train_feat))\n",
    "print(len(test_feat))\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(train_feat, train_label.astype(int))\n",
    "pred = clf.predict(test_feat)\n",
    "print(\"Accuracy = \", accuracy_score(test_label.astype(int), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3369314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056198590190297\n"
     ]
    }
   ],
   "source": [
    "# Cross validation for decision tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "accuracy = cross_val_score(clf,feature_df, label_df.astype(int), cv=10)\n",
    "print(accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ad004",
   "metadata": {},
   "source": [
    "We needed to see how our model would look if we used other classification techniques. We also realized that we should be checking the precision and recall of the model as well. For our next model, we decided to used K-nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "670f92a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38619 13700]\n",
      " [12089 36199]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75     52319\n",
      "           1       0.73      0.75      0.74     48288\n",
      "\n",
      "    accuracy                           0.74    100607\n",
      "   macro avg       0.74      0.74      0.74    100607\n",
      "weighted avg       0.74      0.74      0.74    100607\n",
      "\n",
      "0.8285805055934802\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "ss = StandardScaler()\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "pl = Pipeline(steps=[(\"ss\", ss), (\"pca\", pca), (\"knn\", knn)])\n",
    "\n",
    "scores = cross_val_score(pl, feature_df.astype(int), label_df.astype(int), cv=5)\n",
    "predictions = cross_val_predict(knn, feature_df.astype(int), label_df.astype(int), cv=5)\n",
    "cf = confusion_matrix(label_df.astype(int), predictions)\n",
    "print(confusion_matrix(label_df.astype(int), predictions))\n",
    "print(classification_report(label_df.astype(int), predictions))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f9a7c",
   "metadata": {},
   "source": [
    "For our final model, we decided to use Naive Bayes with a 10 fold cross validation. This model produced our lowest accuracy but it had the highest recall. Here were our results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e94f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 10 fold cv with Naive Bayes:  0.7957498029416188\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "nb_scores = cross_val_score(classifier, feature_df.astype(int), label_df.astype(int), cv=10)\n",
    "print(\"Average accuracy for 10 fold cv with Naive Bayes: \", nb_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5235e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38182 14137]\n",
      " [ 6412 41876]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79     52319\n",
      "           1       0.75      0.87      0.80     48288\n",
      "\n",
      "    accuracy                           0.80    100607\n",
      "   macro avg       0.80      0.80      0.80    100607\n",
      "weighted avg       0.80      0.80      0.80    100607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "predictions = cross_val_predict(classifier, feature_df.astype(int), label_df.astype(int), cv=10)\n",
    "print(confusion_matrix(label_df.astype(int), predictions))\n",
    "print(classification_report(label_df.astype(int), predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca047da",
   "metadata": {},
   "source": [
    "## Conclusion ##\n",
    "We decided recall would be more important for our dataset compared to precision and accuracy because recall in this scenario is out of the animals that were adopted, how many were actually classified as adopted with our models. This is important because if we accidentally labelled an animal that could of had a high chance at adoption as 'Not Adopted', this could lead to bad consequences for that animal (i.e. euthanasia). Because of this reason, we decided that our naive bayes model was the best as it gave us the highest recall of .87.\n",
    "\n",
    "After finishing this project, we realized that we spent the most amount of time on feature selection and data preperation because it was really hard for us to figure out the justification of getting rid our of some of our features. We spent a lot of time debating which ones we should keep and which ones we should get rid of. The most challenging part of this project was figuring out how to deal with the categorical data because the majority of our features were categorical. We attempted to one hot encoding first; however, there were so many categories for some features (ex. breed, color). We realized that using one hot encoding just increased our dimensionality which is something we wanted to avoid. After long debate, we decided that factorization would be best for our dataset. Something interesting that we found looking at our dataset was that there was a bat at the shelter! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524dd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
